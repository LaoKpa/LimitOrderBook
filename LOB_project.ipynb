{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn import metrics\n",
    "# import cvxopt # <- installation via conda recommended\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import nltk\n",
    "import scipy.optimize as sopt\n",
    "import scipy.stats as sstats\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using LOB (Limit Order Book) data from London stock market, September 2013.\n",
    "Every row of our data represent all active ask and bid orders in some moment on time. Row can be describe as below:\n",
    "\n",
    "date time 'BID' $p_{b1}$ $w_{b1}$ $p_{b2}$ $w_{b2}$ ... $p_{bn}$ $w_{bn}$ 'ASK' $p_{a1}$ $w_{a1}$ $p_{a2}$ $w_{a2}$ ... $p_{am}$ $w_{am}$,\n",
    "where $p_b$, $w_b$ are prices and size of bid order and $p_a$, $w_a$ are prives and sizes of ask order. Prices $p_x$ are sorted ascending.\n",
    "\n",
    "LOB data are often represented as 3-element tuples $(p_x,w_x,t_x)$, where $p_x,w_x,t_x$ represent price,size and time of $x-th$ order and $w_x$ is greater than zero for ask order.\n",
    "\n",
    "In our case it will be batter to represent data as a list in which every element is tuple of bid and ask orders lists. Bid and ask lists consist of $(p_x,w_x)$ tuples, and $w_x > 0$ for all orders.\n",
    "\n",
    "We consider orders from $8:30$ to $16:30$ to eliminate abnormal trading behaviour that can occur shortly after the opening auction or shortly before closing auction.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path,start_time=83000000,stop_time=163000000):\n",
    "    X = []\n",
    "    with open(path,newline='') as file:\n",
    "        csv_reader = csv.reader(file,delimiter='\\t')\n",
    "        for row in csv_reader:\n",
    "            date,time = map(int,row[0].split(' '))\n",
    "            if time < start_time or time > stop_time:\n",
    "                continue\n",
    "            \n",
    "            line = 2\n",
    "            ASK_list = []\n",
    "            BID_list = []\n",
    "            while line < len(row):\n",
    "                if row[line] == 'ASK':\n",
    "                    break\n",
    "                p,w = map(float,row[line:line+2])\n",
    "                BID_list.append((p,w))\n",
    "                line += 2\n",
    "            line += 1\n",
    "            while line < len(row):\n",
    "                p,w = map(float,row[line:line+2])\n",
    "                ASK_list.append((p,w))\n",
    "                line += 2\n",
    "            \n",
    "            X.append((BID_list,ASK_list))\n",
    "\n",
    "    return X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\Projekt_ED\\OrderBookSnapshots.csv\"\n",
    "data = load_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4810"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data process functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a given time $t$, the bid price $b(t)$ is the highest stated price among active buy orders,  \n",
    "<center>$b(t) = \\max_{x \\in BIDlist(t)} p_x $</center>  \n",
    "and the ask price $a(t)$ is the lowest stated price among active sell orders,  \n",
    "<center>$a(t) = \\min_{x \\in ASKlist(t)} p_x $</center>  \n",
    "The mid price at time $t$ is  \n",
    "<center>$m(t) = \\frac{a(t)+b(t)}{2} $</center>  \n",
    "  \n",
    "The bid size $n_b(t)$ is total size of active buy orders with price equal to bid price  \n",
    "<center>$n_b(t) = \\sum_{x \\in BIDlist(t) | px = b(t)} w_x $</center>  \n",
    "and ask size $n_b(t)$ is total size of active sell orders with price equal to ask price  \n",
    "<center>$n_a(t) = \\sum_{x \\in ASKlist(t) | px = a(t)} w_x $</center>  \n",
    "  \n",
    "At a given time $t$, the queue imbalance $I(t)$ is normalized difference between $n_b(t)$ and $n_a(t)$  \n",
    "<center>$I(t) = \\frac{n_b(t) - n_a(t)}{n_b(t) + n_a(t)} $</center>  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can expend those definitions considering k highest (lowest) bid (ask) prices.\n",
    "<center>$b_k(t) = k-th$ highest price $\\in BIDlist(t)$</center>  \n",
    "   \n",
    "<center>$a_k(t) = k-th$ lowest price $\\in ASKlist(t)$</center>  \n",
    "  \n",
    "<center>$n_{k,b}(t) = \\sum_{x \\in BIDlist(t) | px \t\\geqslant b_k(t)} w_x $</center>  \n",
    "  \n",
    "<center>$n_{k,a}(t) = \\sum_{x \\in ASKlist(t) | px \\leqslant a_k(t)} w_x $</center>  \n",
    "  \n",
    "At a given time $t$, the $k-th$ queue imbalance $I_k(t)$ is normalized difference between $n_{k,b}(t)$ and $n_{k,b}(t)$  \n",
    "<center>$I_k(t) = \\frac{n_{k,b}(t) - n_{k,a}(t)}{n_{k,b}(t) + n_{k,a}(t)} $</center>  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bid_price(data,t):\n",
    "    return data[t][0][-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_price(data,t):\n",
    "    return data[t][1][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mid_price(data,t):\n",
    "    return (bid_price(data,t) + ask_price(data,t))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bid_size(data,t):\n",
    "    return data[t][0][-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_size(data,t):\n",
    "    return data[t][1][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queue_imbalance(data,t):\n",
    "    nb = bid_size(data,t)\n",
    "    na = ask_size(data,t)\n",
    "    return (nb-na)/(nb+na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queue_imbalance_k(data,t,k=2):\n",
    "    sb = 0\n",
    "    sa = 0\n",
    "    for i in range(k):\n",
    "        sb += data[t][0][-(i+1)][1]\n",
    "        sa += data[t][1][i][1]\n",
    "    return (sb-sa)/(sb+sa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target defining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dejwo opisz to dobrze\n",
    "<center>$T = [t_x | m(t_x) \\neq m(t_{x-1})] $</center>\n",
    "<center>$N = |T| $</center>\n",
    "<center>where $t_x$ are next times in our snapshots data</center>\n",
    "  \n",
    "<center>$targets = [1$ if $m(t_{x+1}) > m(t_{x})$ else $0$ for $t_x \\in T]$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_and_target(data):\n",
    "    T = [0]\n",
    "    target = []\n",
    "    for t in range(1,len(data)):\n",
    "        t_1 = T[-1]\n",
    "        mt = mid_price(data,t)\n",
    "        mt_1 = mid_price(data,t_1)\n",
    "        if mt != mt_1:\n",
    "            T.append(t)\n",
    "            if mt > mt_1:\n",
    "                target.append(1)\n",
    "            else:\n",
    "                target.append(0)\n",
    "    return np.array(T[:-1]),np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "T,target = get_time_and_target(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data matrix defining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define our data matrix.\n",
    "\\begin{bmatrix}\n",
    "    I_1(t_0) & I_2(t_0) &I_3(t_0) & \\dots  & I_K(t_0) \\\\\n",
    "    I_1(t_1) & I_2(t_1) &I_3(t_1) & \\dots  & I_K(t_1) \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    I_1(t_N) & I_2(t_N) &I_3(t_N) & \\dots  & I_K(t_N) \\\\\n",
    "\\end{bmatrix}\n",
    "  \n",
    "We can notice, that for $K=1$ our data matrix is equal to:\n",
    "\\begin{bmatrix}\n",
    "    I(t_0) \\\\\n",
    "    I(t_1) \\\\\n",
    "    \\vdots \\\\\n",
    "    I(t_N) \\\\\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 2\n",
    "X = np.array([[queue_imbalance_k(data,t,k) for k in range(1,K+1)] for t in T])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, target, test_size=0.2, random_state=42,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(preds,Y,name):\n",
    "    print(name)\n",
    "    acc = np.mean(preds == Y)\n",
    "    print(f\"Acc: {acc}\")\n",
    "    M = metrics.confusion_matrix(preds,Y)\n",
    "    N = np.sum(M)\n",
    "    print('\\nConfusion matrix:')\n",
    "    print(M)\n",
    "    print(f'\\nTrue negative (rating = 1): {M[0][0]}')\n",
    "    print(f'True positive (rating = 10): {M[1][1]}')\n",
    "    print(f'False negative: {M[0][1]}')\n",
    "    print(f'False positive: {M[1][0]}')\n",
    "    return M,N,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to predict if $m_{t+1} > m_t$ using data vector\n",
    "\\begin{bmatrix}\n",
    "    I_1(t) & I_2(t) &I_3(t) & \\dots  & I_K(t) \\\\\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using logistic regression.\n",
    "Using logistic regression we can calculate probability of the sample $x$ belonging to class 1\n",
    "<center>$p(y=1|x) = \\sigma(\\theta^Tx) = \\frac{1}{1 + e^{-\\theta^Tx}}$</center>  \n",
    "  \n",
    "We can observe that:\n",
    "$ \\begin{align} p(y=y^{(i)}|x^{(i)};\\Theta) &= \\cases{p(y=1|x;\\Theta) &if $y^{(i)}=1$ \\\\ 1-p(y=1|x;\\Theta) &if $y^{(i)}=0$} \\\\ &= p(y=1|x;\\Theta)^{y^{(i)}}(1-p(y=1|x;\\Theta))^{(1-y^{(i)})} \\\\ &= \\sigma(\\Theta^Tx)^{y^{(i)}}(1-\\sigma(\\Theta^Tx))^{(1-y^{(i)})} \\end{align} $\n",
    "  \n",
    "Therefore the negative log likelihood ($nll$) is:$$\n",
    "\\begin{split}\n",
    "nll(\\Theta) &= -\\sum_{i=1}^{N} y^{(i)} \\log \\sigma(\\Theta^Tx) + (1-y^{(i)})\\log(1-\\sigma(\\Theta^Tx)) = \\\\\n",
    "&= -\\sum_{i=1}^{N}y^{(i)}\\log p(y=1|x^{(i)}; \\Theta) + (1-y^{(i)})\\log  p(y=0|x^{(i)}; \\Theta)\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "So we are searching for $\\theta$:\n",
    "<center>$\\theta = arg\\,max_{\\theta}$ $nll(\\theta) $</center>  \n",
    "  \n",
    "We can consider also logistic regression with regularization, where:$$\n",
    "\\begin{split}\n",
    "nll(\\Theta) &= -\\sum_{i=1}^{N}y^{(i)}\\log p(y=1|x^{(i)}; \\Theta) + (1-y^{(i)})\\log  p(y=0|x^{(i)}; \\Theta) + \\frac{\\lambda}{2} \\sum_{i}\\theta_{i}^{2}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "There are few ways to find $\\theta$. We will consider Newtod-Raphson Method and L-BFGS-B solver. We will compare this with sklearn LogisticRegression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L-BFGS-B solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic_Regression:\n",
    "    def __init__(self, max_iter=500, solver_calls=5,lambda_ = 0.5,Theta=None, solver=sopt.fmin_l_bfgs_b, debug=False):\n",
    "        self.Theta = Theta\n",
    "        self.solver_calls = solver_calls\n",
    "        self.max_iter = max_iter\n",
    "        self.solver = solver\n",
    "        self.debug = debug\n",
    "        self.lambda_ = lambda_\n",
    "    \n",
    "    def __sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))    \n",
    "    \n",
    "    def __logreg_loss(self, Theta, X, Y):\n",
    "        Theta = Theta.astype(np.float64)\n",
    "        X = X.astype(np.float64)\n",
    "        Y = Y.astype(np.float64)\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"Loss calculating... \",end=\"\")\n",
    "        Z = np.dot(Theta,X.T)\n",
    "        if self.debug:\n",
    "            print(f\" Z done... \",end=\"\")\n",
    "        SZ = self.__sigmoid(Z)\n",
    "        Y_ = Y[:,np.newaxis]\n",
    "        nll = -np.sum((Y_*np.log2(SZ+1e-50) + (1-Y_)*np.log2(1-SZ+1e-50)))\n",
    "        nll += (self.lambda_/2) * np.sum(Theta**2)\n",
    "        if self.debug:\n",
    "            print(f\" nll done... \",end=\"\")\n",
    "        grad = np.dot(X.T, (SZ - Y).T ) / len(Y)\n",
    "        grad = grad.reshape(Theta.shape) + self.lambda_ * Theta\n",
    "        if self.debug:\n",
    "            print(f\" grad done... done \")\n",
    "        return nll, grad\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        Theta = self.Theta\n",
    "        if Theta is None:\n",
    "            Theta = np.ones(X.shape[1]+1)\n",
    "        \n",
    "        X_with_ones = np.hstack((np.ones((X.shape[0],1)),X))\n",
    "      \n",
    "        for i in tqdm(range(self.solver_calls), desc='Calculating Theta', position=0):\n",
    "            Theta = self.solver(lambda th: self.__logreg_loss(th, X_with_ones, y), \n",
    "                                Theta, maxiter=self.max_iter)[0]\n",
    "        self.Theta = Theta\n",
    "\n",
    "    def predict(self,X):\n",
    "        X_with_ones = np.hstack((np.ones((X.shape[0],1)),X))\n",
    "        preds = (np.dot(self.Theta,X_with_ones.T) >= 0) * 1\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_solver = Logistic_Regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Theta: 100%|█████████████████████████████████████████████████████████████████| 5/5 [00:17<00:00,  3.57s/it]\n"
     ]
    }
   ],
   "source": [
    "LR_solver.fit(X_train,y_train)\n",
    "preds_train_solver = LR_solver.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data, L-BFGS-B solver, lambda=0.5\n",
      "Acc: 0.5395040369088812\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 739  628]\n",
      " [ 969 1132]]\n",
      "\n",
      "True negative (rating = 1): 739\n",
      "True positive (rating = 10): 1132\n",
      "False negative: 628\n",
      "False positive: 969\n"
     ]
    }
   ],
   "source": [
    "M,N,acc = print_score(preds_train_solver,y_train,\n",
    "                      'Train data, L-BFGS-B solver, lambda=0.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test_solver = LR_solver.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data, L-BFGS-B solver, lambda=0.5\n",
      "Acc: 0.5518433179723502\n",
      "\n",
      "Confusion matrix:\n",
      "[[172 141]\n",
      " [248 307]]\n",
      "\n",
      "True negative (rating = 1): 172\n",
      "True positive (rating = 10): 307\n",
      "False negative: 141\n",
      "False positive: 248\n"
     ]
    }
   ],
   "source": [
    "M,N,acc = print_score(preds_test_solver,y_test,\n",
    "                      'Test data, L-BFGS-B solver, lambda=0.5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newtod-Raphson Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Newton's method is an iterative method for finding the roots of a differentiable function $F$, which are solutions to the equation $F(x) = 0$. For give start approximation $x_n$ we can calculate better approximation of the root:  \n",
    "<center>$x_{n+1} = x_n - \\frac{f(x)}{f'(x)} $</center>  \n",
    "  \n",
    "We can use this method to find root of $F'$, where is local optimum of $F$.  \n",
    "  \n",
    "For given approximation $x_n$ we can calculate better approximation of local optimum:  \n",
    "<center>$x_{n+1} = x_n - \\gamma [f''(x)]^{-1} f'(x) $</center>\n",
    "<center>where $0<\\gamma<1$ </center>\n",
    "<center>$f'(x) = \\nabla f(x) \\in \\mathbb {R} ^{d}$</center>\n",
    "<center>$ f''(x)=\\nabla ^{2}f(x)=H_{f}(x) \\in \\mathbb {R} ^{d\\times d} $</center>  \n",
    "$H_{f}$ is Hessian matrix and $\\gamma$ is step size. We are trying $\\gamma = \\frac{1}{2^k}$ for $k=0...10$ until Wolfe conditions are satisfied.  \n",
    "Wolfe conditions are:\n",
    "\\begin{aligned}{\\textbf {i)}}&\\quad f(\\mathbf {x} _{n}+\\gamma\\mathbf {p} _{n})\\leq f(\\mathbf {x} _{n})+c_{1}\\gamma\\mathbf {p} _{n}^{\\mathrm {T} }\\nabla f(\\mathbf {x} _{n}),\\\\[6pt]{\\textbf {ii)}}&\\quad {-\\mathbf {p} }_{n}^{\\mathrm {T} }\\nabla f(\\mathbf {x} _{n}+\\gamma\\mathbf {p} _{n})\\leq -c_{2}\\mathbf {p} _{n}^{\\mathrm {T} }\\nabla f(\\mathbf {x} _{n}),\\end{aligned}\n",
    "<center>where ${p}_{n}=-\\mathbf {H} ^{-1}\\nabla f(\\mathbf {x} _{n})$</center>  \n",
    "<center>and c1,c2 are parameters, often equal $c_1=0.1$, $c_2=0.9$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_sklearn = LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_sklearn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train_sklearn = LR.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data, sklearn LR, C=1.0\n",
      "Acc: 0.5403690888119954\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 846  732]\n",
      " [ 862 1028]]\n",
      "\n",
      "True negative (rating = 1): 846\n",
      "True positive (rating = 10): 1028\n",
      "False negative: 732\n",
      "False positive: 862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 846,  732],\n",
       "        [ 862, 1028]], dtype=int64), 3468, 0.5403690888119954)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_score(preds_train_sklearn,y_train,\n",
    "                      'Train data, sklearn LR, C=1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test_sklearn = LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data, sklearn LR, C=1.0\n",
      "Acc: 0.5552995391705069\n",
      "\n",
      "Confusion matrix:\n",
      "[[189 155]\n",
      " [231 293]]\n",
      "\n",
      "True negative (rating = 1): 189\n",
      "True positive (rating = 10): 293\n",
      "False negative: 155\n",
      "False positive: 231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[189, 155],\n",
       "        [231, 293]], dtype=int64), 868, 0.5552995391705069)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_score(preds_test_sklearn,y_test,\n",
    "                      'Test data, sklearn LR, C=1.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing different k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1\n",
      "Train: 0.5452710495963091\n",
      "Test: 0.5403225806451613\n",
      "\n",
      "k: 2\n",
      "Train: 0.5403690888119954\n",
      "Test: 0.5576036866359447\n",
      "\n",
      "k: 3\n",
      "Train: 0.5426758938869666\n",
      "Test: 0.5564516129032258\n",
      "\n",
      "k: 4\n",
      "Train: 0.5475778546712803\n",
      "Test: 0.5518433179723502\n",
      "\n",
      "k: 5\n",
      "Train: 0.5461361014994233\n",
      "Test: 0.5495391705069125\n",
      "\n",
      "k: 6\n",
      "Train: 0.5452710495963091\n",
      "Test: 0.5483870967741935\n",
      "\n",
      "k: 7\n",
      "Train: 0.5449826989619377\n",
      "Test: 0.5483870967741935\n",
      "\n",
      "k: 8\n",
      "Train: 0.5446943483275664\n",
      "Test: 0.5483870967741935\n",
      "\n",
      "k: 9\n",
      "Train: 0.5441176470588235\n",
      "Test: 0.5460829493087558\n",
      "\n",
      "k: 10\n",
      "Train: 0.5446943483275664\n",
      "Test: 0.5414746543778802\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for K in range(1,11):\n",
    "    X = np.array([[queue_imbalance_k(data,t,k) for k in range(1,K+1)] for t in T])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, target, test_size=0.2, random_state=42,shuffle=False)\n",
    "    LR = LogisticRegression(solver = 'lbfgs')\n",
    "    LR.fit(X_train,y_train)\n",
    "    preds_train = LR.predict(X_train)\n",
    "    print('k:', K)\n",
    "    print(f'Train: {np.mean(preds_train == y_train)}')\n",
    "    preds = LR.predict(X_test)\n",
    "    print(f'Test: {np.mean(preds == y_test)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing different C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.01\n",
      "Train: 0.5432525951557093\n",
      "Test: 0.5529953917050692\n",
      "\n",
      "C: 0.05\n",
      "Train: 0.5441176470588235\n",
      "Test: 0.5576036866359447\n",
      "\n",
      "C: 0.1\n",
      "Train: 0.5426758938869666\n",
      "Test: 0.5564516129032258\n",
      "\n",
      "C: 0.2\n",
      "Train: 0.5441176470588235\n",
      "Test: 0.5552995391705069\n",
      "\n",
      "C: 0.25\n",
      "Train: 0.5441176470588235\n",
      "Test: 0.5552995391705069\n",
      "\n",
      "C: 0.3\n",
      "Train: 0.5435409457900807\n",
      "Test: 0.5576036866359447\n",
      "\n",
      "C: 0.4\n",
      "Train: 0.5426758938869666\n",
      "Test: 0.5576036866359447\n",
      "\n",
      "C: 0.5\n",
      "Train: 0.5415224913494809\n",
      "Test: 0.5576036866359447\n",
      "\n",
      "C: 0.75\n",
      "Train: 0.5403690888119954\n",
      "Test: 0.5576036866359447\n",
      "\n",
      "C: 0.85\n",
      "Train: 0.5403690888119954\n",
      "Test: 0.5576036866359447\n",
      "\n",
      "C: 0.9\n",
      "Train: 0.5403690888119954\n",
      "Test: 0.5576036866359447\n",
      "\n",
      "C: 1.0\n",
      "Train: 0.5403690888119954\n",
      "Test: 0.5576036866359447\n",
      "\n",
      "C: 1.25\n",
      "Train: 0.5403690888119954\n",
      "Test: 0.5576036866359447\n",
      "\n",
      "C: 1.5\n",
      "Train: 0.5403690888119954\n",
      "Test: 0.5576036866359447\n",
      "\n",
      "C: 2.0\n",
      "Train: 0.5403690888119954\n",
      "Test: 0.5564516129032258\n",
      "\n",
      "C: 5.0\n",
      "Train: 0.5403690888119954\n",
      "Test: 0.5552995391705069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for C in [0.01,0.05,0.1,0.2,0.25,0.3,0.4,0.5,0.75,0.85,0.9,1.0,1.25,1.5,2.0,5.0]:\n",
    "    X = np.array([[queue_imbalance_k(data,t,k) for k in range(1,3)] for t in T])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, target, test_size=0.2, random_state=42,shuffle=False)\n",
    "    LR = LogisticRegression(solver = 'lbfgs',C=C)\n",
    "    LR.fit(X_train,y_train)\n",
    "    preds_train = LR.predict(X_train)\n",
    "    print('C:', C)\n",
    "    print(f'Train: {np.mean(preds_train == y_train)}')\n",
    "    preds = LR.predict(X_test)\n",
    "    print(f'Test: {np.mean(preds == y_test)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Receiver operating characteristic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "279.273px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
